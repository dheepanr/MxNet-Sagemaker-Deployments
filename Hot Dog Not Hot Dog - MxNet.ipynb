{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "* This notebook covers how to utilize Sagemaker NEO and Sagemaker Elastic Inference (EI)\n",
    "* In this example, we build a ResNet transfer learning model to predict hot dog/not hot dog [a la Silicon Valley](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=2ahUKEwieq5LR5_jkAhXFY98KHdvcBXEQwqsBMAB6BAgJEAQ&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DACmydtFDTGs&usg=AOvVaw1OQiCPPVe3B2B6ndhvDGnq)\n",
    "* Note to run through this notebook Sagemaker P2 instances and a notebook with at least 10 gb of disk space is needed\n",
    "* We utilize the Food101 dataset to create the hot dog/not hot dog dataset\n",
    "* By the end of the notebook we show how inference speed are measured against cost for a ResNet Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download and unzip the Food101 dataset in a terminal using the code below \n",
    "\n",
    "`cd Sagemaker`\n",
    "\n",
    " `wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz`\n",
    " \n",
    " `tar -zxvf food-101.tar.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load necessary packages\n",
    "import json\n",
    "from glob import glob\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from mxnet import gluon\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/32/5144caf0478b1f26bd9d97f510a47336cf4ac0f96c6bc3b5af20d4173920/tqdm-4.40.2-py2.py3-none-any.whl (55kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 26.1MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.40.2\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to create food101 folder with contents first\n",
    "os.chdir('food-101')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = json.load(open('meta/train.json'))\n",
    "test_json = json.load(open('meta/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directories for the hot dog/not hot dog dataset\n",
    "os.makedirs('../hotdog_not_hotdog/train/hot_dog/', exist_ok=True)\n",
    "os.makedirs('../hotdog_not_hotdog/test/hot_dog/', exist_ok=True)\n",
    "\n",
    "os.makedirs('../hotdog_not_hotdog/train/not_hotdog/', exist_ok=True)\n",
    "os.makedirs('../hotdog_not_hotdog/test/not_hotdog/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "def move_and_rename(json, dest, n_images):\n",
    "    '''\n",
    "    This function takes a json of file names, copies and renames these files into new directories\n",
    "    All images are copied for hot dog files, the function randomly copies other images for number of n_images\n",
    "    json : dict, dict of filenames\n",
    "    dest, string, local folder where to deposit files\n",
    "    n_images, int, number of images to randomly sample for not hot dog images\n",
    "    '''\n",
    "    json_copy = copy.deepcopy(json)\n",
    "    hotdog_images = json_copy['hot_dog']\n",
    "    for i in hotdog_images:\n",
    "        shutil.copyfile('images/{}.jpg'.format(i), '../hotdog_not_hotdog/{}/{}.jpg'.format(dest,i))\n",
    "    json_copy.pop('hot_dog')\n",
    "    other_foods = list(json_copy.keys())\n",
    "    cnt = 0\n",
    "    for i in tqdm(list(range(n_images))):\n",
    "        random_indexer = random.randint(0, len(other_foods)-1)\n",
    "        other_class_imgs = json_copy[other_foods[random_indexer]]\n",
    "        img_indexer = random.randint(0, len(other_class_imgs)-1)\n",
    "        selected_image = other_class_imgs[img_indexer]\n",
    "        destination_name = 'not_hotdog/{}'.format(cnt)\n",
    "        shutil.copyfile('images/{}.jpg'.format(selected_image), '../hotdog_not_hotdog/{}/{}.jpg'.format(dest,destination_name))\n",
    "        other_class_imgs.pop(img_indexer)\n",
    "        # delete used image from list of possibilities\n",
    "        json_copy[other_foods[random_indexer]] = other_class_imgs\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:01<00:00, 739.61it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 915.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# create dataset folders\n",
    "move_and_rename(train_json, 'train', 750)\n",
    "move_and_rename(test_json, 'test', 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validate the number of images in the folders\n",
    "len(glob('../hotdog_not_hotdog/train/hot_dog/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob('../hotdog_not_hotdog/test/not_hotdog/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Create Sagemaker session and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Data\n",
    "\n",
    "* Sagemaker expects the data to be in an s3 path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-east-1-178197730631/data/DEMO-hotdog_not_hotdog\n"
     ]
    }
   ],
   "source": [
    "inputs = sagemaker_session.upload_data(path='../hotdog_not_hotdog', key_prefix='data/DEMO-hotdog_not_hotdog')\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on the MxNet Script\n",
    "\n",
    "* The 'hotdog-not-hotdog.py' file has functions for training and deploying the model\n",
    "    * The model_fn and transform_fn's automatically deploy on the correct context based on environment\n",
    "    * For elastic inference data must be placed on `mxnet.eia()` for both data and model\n",
    "* Note that the model has the following hyperparameters for training\n",
    "    * batch_size, int, number for batch size\n",
    "    * epochs, int, number of epochs to run training\n",
    "    * learning rate, float, the learning rate for the model\n",
    "    * momentum, float, momentum for the SGD algorithm\n",
    "    * wd, float, weight decay parameter for model params\n",
    "    * resnet_size, str, size of resnet to use one of 18, 34, 50, 101, 152\n",
    "    \n",
    "\n",
    "* As a opposed to a standard MxNet script to use Sagemaker Neo special functions need to be added\n",
    "    * These are seen at the bottom of the script (neo_postprocess and neo_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Job\n",
    "\n",
    "* Instantiate the Sagemaker MxNet estimator with the role, instance type, number of instances and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MXNet('../hotdog-not-hotdog-mxnet.py',\n",
    "          role=role, \n",
    "          framework_version='1.4.1',\n",
    "          train_instance_count=1,\n",
    "          train_instance_type='ml.p3.2xlarge',\n",
    "          py_version='py3',\n",
    "          hyperparameters={'batch_size': 32,\n",
    "                           'epochs': 6,\n",
    "                           'learning_rate': 0.01,\n",
    "                           'momentum': 0.9,\n",
    "                           'resnet_size':'101'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fit the model against the s3 path specified earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.fit(\"s3://sagemaker-us-east-1-178197730631/data/DEMO-hotdog_not_hotdog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the Models through Sagemaker Neo\n",
    "\n",
    "* Sagemaker NEO compiles the models to optimize them for specific ml instance types in Sagemaker\n",
    "* Here we create both a GPU optimized model and a CPU optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/'.join(m.output_path.split('/')[:-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "??........!"
     ]
    }
   ],
   "source": [
    "compiled_model_gpu = m.compile_model(target_instance_family='ml_p2', input_shape={'data':[1,3,512,512]}, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?........!"
     ]
    }
   ],
   "source": [
    "compiled_model_p3 = m.compile_model(target_instance_family='ml_p3', input_shape={'data':[1,3,512,512]}, output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?...............................................!"
     ]
    }
   ],
   "source": [
    "compiled_model_cpu = m.compile_model(target_instance_family='ml_c5', input_shape={'data':[1,3,512,512]}, output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "\n",
    "* We deploy the models with Sagemaker's one click deployment with a few modifications to the input and output serialization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Different Model Deployments\n",
    "\n",
    "* Different Sagemaker Models need to be created to deploy on different container configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.mxnet import MXNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_location = f\"{m.output_path}{m.latest_training_job.job_name}/output/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cpu = MXNetModel(model_data=model_output_location, entry_point='../hotdog-not-hotdog-mxnet.py', role=role,\n",
    "                      py_version='py3', framework_version='1.4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p2 = MXNetModel(model_data=model_output_location, entry_point='../hotdog-not-hotdog-mxnet.py', role=role,\n",
    "                      py_version='py3', framework_version='1.4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_p3 = MXNetModel(model_data=model_output_location, entry_point='../hotdog-not-hotdog-mxnet.py', role=role,\n",
    "                      py_version='py3', framework_version='1.4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_g4 = MXNetModel(model_data=model_output_location, entry_point='../hotdog-not-hotdog-mxnet.py', role=role,\n",
    "                      py_version='py3', framework_version='1.4.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eia = MXNetModel(model_data=model_output_location, entry_point='../hotdog-not-hotdog-mxnet.py', role=role,\n",
    "                      py_version='py3', framework_version='1.4.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inference Code\n",
    "\n",
    "* Our files need to be normalized to ImageNet values for mean and standard deviations and cropped to be 224x224\n",
    "* We define this code and a selection of images for use with our models\n",
    "* Requires opencv package\n",
    "* If this is not installed run the following code in a notebook cell\n",
    "\n",
    "`import sys\n",
    "!{sys.executable} -m pip install opencv-python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob('../hotdog_not_hotdog/test/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_selection = [filenames[random.randint(0,499)] for x in range(0,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import cv2 \n",
    "\n",
    "def predict_hotdog(endpoint, filenames):\n",
    "    '''\n",
    "    Function to preprocess and predict a list of images\n",
    "    endpoint, str, Sagemaker endpoint\n",
    "    filenames, list, list of images (local file locations)\n",
    "    '''\n",
    "    resps = []\n",
    "    for img in filenames:\n",
    "        img_np = cv2.imread(img)\n",
    "        img_np = cv2.resize(img_np,(512,512))\n",
    "        img_np = img_np.transpose(2, 0, 1)\n",
    "        output_img = np.expand_dims(img_np, axis=0)\n",
    "        resp = endpoint.predict(output_img)\n",
    "        resps.append(resp)\n",
    "    return resps\n",
    "\n",
    "def numpy_bytes_serializer(data):\n",
    "    '''\n",
    "    function to serialize data for sagemaker neo endpoints\n",
    "    '''\n",
    "    f = io.BytesIO()\n",
    "    np.save(f, data)\n",
    "    f.seek(0)\n",
    "    return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Inference on A Variety of Sagemaker Deployments\n",
    "\n",
    "* We showcase how regular EI, Neo, and different ML ec2 types can impact endpoint latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2 Instances\n",
    "\n",
    "P2 instances are intended for general-purpose GPU compute applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor_p2 = model_p2.deploy(initial_instance_count=1,\n",
    "                        instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.8860937'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model onto instance\n",
    "predict_hotdog(predictor_p2, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1 s ± 305 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 2.345171244939168\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(predictor_p2, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_p2.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3 Instances\n",
    "\n",
    "P3\n",
    "instances are the newest generation of ec2 intended for general-purpose GPU compute applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor_p3 = model_p3.deploy(initial_instance_count=1,\n",
    "                        instance_type='ml.p3.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.704241'}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model onto instance\n",
    "predict_hotdog(predictor_p3, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.4 s ± 170 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 1.9120223760604858\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(predictor_p3, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_p3.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C5 Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C5 instances are optimized for compute-intensive workloads and deliver cost-effective high performance at a low price per compute ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor_c5 = model_cpu.deploy(initial_instance_count=1,\n",
    "                        instance_type='ml.c5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.88609374'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model onto instance\n",
    "predict_hotdog(predictor_c5, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.8 s ± 410 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 6.041615438461304\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(predictor_c5, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_c5.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G4 Instances \n",
    "\n",
    "G4 instances are designed to help accelerate machine learning inference and graphics-intensive workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor_g4 = model_g4.deploy(initial_instance_count=1,\n",
    "                        instance_type='ml.g4dn.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.88609356'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model onto instance\n",
    "predict_hotdog(predictor_g4, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.9 s ± 217 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 1.8551597436269125\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(predictor_g4, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_g4.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Inference\n",
    "\n",
    "Amazon Elastic Inference allows you to attach low-cost GPU-powered acceleration to Amazon EC2 and Amazon SageMaker instances or Amazon ECS tasks to reduce the cost of running deep learning inference by up to 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor_ei = model_eia.deploy(initial_instance_count=1, \n",
    "                        instance_type='ml.c5.large',\n",
    "                            accelerator_type='ml.eia2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.88609356'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_hotdog(predictor_ei, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.8 s ± 620 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 2.4239836931228638\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(predictor_ei, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_ei.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Neo\n",
    "\n",
    "Amazon SageMaker Neo enables developers to train machine learning models once and run them anywhere in the cloud and at the edge. Amazon SageMaker Neo optimizes models to run up to twice as fast, with less than a tenth of the memory footprint, with no loss in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo Optimized C5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "compiled_predictor = compiled_model_cpu.deploy(initial_instance_count=1, \n",
    "                                               instance_type='ml.c5.xlarge')\n",
    "\n",
    "compiled_predictor.content_type = 'application/vnd+python.numpy+binary'\n",
    "compiled_predictor.serializer = numpy_bytes_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.8860937'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_hotdog(compiled_predictor, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.7 s ± 1.97 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 2.5276662866274515\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(compiled_predictor, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo Optimized G4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import npy_serializer, json_deserializer, json_serializer\n",
    "compiled_predictor = compiled_model_gpu.deploy(initial_instance_count=1, \n",
    "                                               instance_type='ml.g4dn.xlarge')\n",
    "\n",
    "compiled_predictor.content_type = 'application/vnd+python.numpy+binary'\n",
    "compiled_predictor.serializer = numpy_bytes_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.8860937'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_hotdog(compiled_predictor, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.67 s ± 127 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 0.3110075076421102\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(compiled_predictor, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo Optimized P2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import npy_serializer, json_deserializer, json_serializer\n",
    "compiled_predictor = compiled_model_gpu.deploy(initial_instance_count=1, \n",
    "                                               instance_type='ml.p2.xlarge')\n",
    "\n",
    "compiled_predictor.content_type = 'application/vnd+python.numpy+binary'\n",
    "compiled_predictor.serializer = numpy_bytes_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.8860937'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_hotdog(compiled_predictor, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.19 s ± 149 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 0.6050745129585267\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(compiled_predictor, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo Compiled P3 Instances\n",
    "\n",
    "P2 instances are intended for general-purpose GPU compute applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import npy_serializer, json_deserializer, json_serializer\n",
    "compiled_predictor = compiled_model_p3.deploy(initial_instance_count=1, \n",
    "                                               instance_type='ml.p3.2xlarge')\n",
    "\n",
    "compiled_predictor.content_type = 'application/vnd+python.numpy+binary'\n",
    "compiled_predictor.serializer = numpy_bytes_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'predicted_class': 'not_hot_dog', 'confidence': '0.70424116'}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_hotdog(compiled_predictor, random_selection[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24 s ± 35.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "Total Time 0.2618632833162943\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "%timeit -n 1 predict_hotdog(compiled_predictor, random_selection)\n",
    "print(f\"Total Time {(time.time()-t1)/60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_p3.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
